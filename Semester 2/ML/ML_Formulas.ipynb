{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 1\n",
    "\n",
    "### What is Machine Learning?\n",
    "\n",
    "Program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E.\n",
    "To have a learning problem, we must identify:\n",
    "- class of tasks T\n",
    "- performance measure P\n",
    "- source of experience E\n",
    "\n",
    "Traditional programming vs Machine Learning\n",
    "- Traditional programming: (data) + (program) = (output)\n",
    "- Machine Learning: (data) + (output) = (program)\n",
    "\n",
    "#### Table with learning tasks, performance measures and experience sources\n",
    "\n",
    "| Task | Performance Measure | Experience Source |\n",
    "| --- | --- | --- |\n",
    "| Email spam filter | Accuracy of the filter | User marks emails as spam/not spam |\n",
    "| Handwritten digit recognition | Accuracy of the classifier | User provides examples of digits |\n",
    "| Self-driving car | Safety and efficiency of the car | User drives the car |\n",
    "| Playing checkers | % of games won against opponent | Games played against itself |\n",
    "\n",
    "#### When do we use / not use Machine Learning?\n",
    "Used when:\n",
    "- lots of hand-tuning, long lists of rules, or hard to define rules\n",
    "- complex / fluctuating environment\n",
    "- expert knowledge does not exist, or is difficult to obtain\n",
    "- models based on huge amount of data, must be customized to each individual\n",
    "\n",
    "Not used when:\n",
    "- simple, static environment, well-defined rules\n",
    "- no uncertainty in the environment\n",
    "- expert knowledge is available\n",
    "\n",
    "### Machine Learning Process\n",
    "\n",
    "| Step | Description |\n",
    "| --- | --- |\n",
    "| 1. Define the Problem     | Clearly define the problem statement, including the goal and the target variable(s).<br> Identify the available resources, constraints, and relevant stakeholders.<br> Understand the domain knowledge and business context to ensure the problem's relevance. |\n",
    "| 2. Data Collection        | Determine the data requirements based on the problem definition.<br> Identify potential data sources and acquire the necessary datasets.<br> Ensure data quality by performing data validation, cleaning, and handling missing values or outliers. |\n",
    "| 3. Data Exploration       | Perform statistical analysis, such as summary statistics and data distributions.<br> Visualize the data through plots, histograms, scatterplots, or heatmaps.<br> Identify correlations, patterns, and outliers within the dataset.<br> Conduct feature correlation analysis to understand relationships between variables. |\n",
    "| 4. Feature Engineering    | Select relevant features based on domain knowledge and exploration.<br> Handle categorical variables through techniques like one-hot encoding or ordinal encoding.<br> Scale numerical features to a common range or apply normalization techniques.<br> Create new features by transforming or combining existing ones (e.g., feature interactions, polynomial features). |\n",
    "| 5. Model Selection        | Identify the problem type (classification, regression, clustering, etc.).<br> Consider the characteristics of the dataset (e.g., size, dimensionality) and the assumptions of different algorithms.<br> Evaluate various algorithms and choose the one that best suits the problem and data. |\n",
    "| 6. Model Training         | Split the data into training and testing sets (e.g., using random sampling or time-based splitting).<br> Apply the chosen algorithm to the training data and optimize its hyperparameters.<br> Evaluate the model's performance on the testing set using appropriate metrics.<br> Repeat the training process with different algorithms or parameter settings if necessary. |\n",
    "| 7. Model Evaluation       | Calculate evaluation metrics such as accuracy, precision, recall, F1 score, or mean squared error.<br> Perform cross-validation or holdout validation to estimate the model's performance on unseen data.<br> Analyze the model's strengths, weaknesses, and potential biases.<br> Consider business requirements and domain-specific metrics for a comprehensive evaluation. |\n",
    "| 8. Model Optimization     | Fine-tune the model's hyperparameters through techniques like grid search, random search, or Bayesian optimization.<br> Regularize the model to prevent overfitting using techniques like L1/L2 regularization or dropout.<br> Explore ensemble methods, such as bagging or boosting, to improve model performance.<br> Use feature selection techniques to remove irrelevant or redundant features. |\n",
    "| 9. Model Deployment       | Prepare the model for deployment by saving its trained parameters and associated preprocessing steps.<br> Integrate the model into an application, system, or cloud infrastructure.<br> Design and implement an API for making predictions using the deployed model.<br> Ensure the model's scalability, robustness, and security in a production environment. |\n",
    "| 10. Monitoring and Maintenance | Continuously monitor the model's performance in real-world scenarios.<br> Collect feedback and track performance metrics to detect any degradation or concept drift.<br> Retrain the model periodically with new data to keep it up-to-date and maintain its accuracy.<br> Conduct regular model audits and updates as needed. |\n",
    "| 11. Iteration and Improvement | Regularly revisit and refine the model as new insights are gained, data quality improves, or new techniques emerge.<br> Incorporate feedback from stakeholders and address any limitations or shortcomings.<br> Continuously experiment with new algorithms or approaches to improve the model's performance and adapt to evolving requirements. |\n",
    "\n",
    "#### Types of learning:\n",
    "- Supervised (inductive) learning\n",
    "    - given training data, desired outputs (labels)\n",
    "    - learn a function that maps inputs to outputs\n",
    "    - types:\n",
    "        - classification (predict class or category, discrete value)\n",
    "            - binary classification (2 classes)\n",
    "            - multi-class classification (more than 2 classes)\n",
    "        - regression (predict continuous value)\n",
    "- Unsupervised (deductive) learning\n",
    "    - given training data, no desired outputs\n",
    "    - learn a function that describes hidden structure from unlabeled data\n",
    "- Semi-supervised learning\n",
    "    - given training data, some desired outputs\n",
    "    - learn a function that maps inputs to outputs\n",
    "- Reinforcement learning\n",
    "    - rewards from sequence of actions\n",
    "    - learn a function that maximizes a reward signal\n",
    "\n",
    "High level, general comparison table:\n",
    "\n",
    "|                       | Supervised Learning               | Unsupervised Learning          | Semi-Supervised Learning             | Reinforcement Learning                    |\n",
    "|-----------------------|-----------------------------------|--------------------------------|--------------------------------------|------------------------------------------|\n",
    "| Data                  | Labelled                          | Unlabelled                     | Mix of Labelled and Unlabelled       | Depends on State and Reward              |\n",
    "| Task                  | Prediction                        | Pattern Recognition            | Prediction                           | Sequential Decision Making               |\n",
    "| Example Algorithms    | Linear Regression, SVM, Neural Networks | Clustering, K-Means, PCA | Self-Training, Multi-View Training   | Q-Learning, SARSA, DQN                    |\n",
    "| Feedback              | Direct                            | None                           | Partial                              | Reward-based                              |\n",
    "| Goal                  | Minimize Error on Given Labels    | Discover Hidden Structure      | Better Generalization Accuracy       | Maximize Cumulative Reward                |\n",
    "| Typical Use Case      | Image Recognition, Email Spam Detection | Customer Segmentation, Anomaly Detection | Web Content Classification, Bioinformatics | Game AI, Robot Navigation, Real-time Decisions |\n",
    "| Training Efficiency   | High (due to direct feedback)     | Medium (no feedback)           | Varies (depends on labeled/unlabeled ratio) | Typically slow, trial and error-based      |\n",
    "| Complexity of Problem | Low-Medium                        | High                           | Medium-High                          | High                                      |\n",
    "| Real-time Adaptation  | Not Typically                     | Not Typically                  | Not Typically                        | Yes, using online learning                 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Formulas\n",
    "\n",
    "### What is Machine Learning?\n",
    "A computer program is said to learn from experience $E$ with respect to some class of tasks $T$ and performance measure $P$, if its performance at tasks in $T$, as measured by $P$, improves with experience $E$.\n",
    "Example: playing checkers.\n",
    "$E$ = the experience of playing many games of checkers\n",
    "$T$ = the task of playing checkers\n",
    "$P$ = the probability that the program will win the next game\n",
    "\n",
    "Traditional programming : (data) + (program) = (output)\n",
    "Machine Learning : (data) + (output) = (program)\n",
    "\n",
    "ML is used when:\n",
    "- lots of hand-tuning, long lists of rules, or hard to define rules\n",
    "- complex / fluctuating environment\n",
    "- expert knowledge does not exist, or is difficult to obtain\n",
    "- models based on huge amount of data, must be customized to each individual\n",
    "\n",
    "It is based on learning a function $h$ that approximates $y$ as a function of $x$: $$h: X \\rightarrow Y$$ where $X$ is the input space and $Y$ is the output space.\n",
    "Steps:\n",
    "1. Define the objective of the problem\n",
    "2. Collect data\n",
    "3. Prepare / preprocess data\n",
    "4. Explorative data analysis\n",
    "5. Building a machine learning model\n",
    "6. Model evaluation and optimization\n",
    "7. Deploy the model, predict new values\n",
    "\n",
    "#### Types of learning:\n",
    "1. Supervised (inductive) learning\n",
    "    - given training data, desired outputs (labels)\n",
    "    - learn a function that maps inputs to outputs\n",
    "    - types:\n",
    "        - classification (predict class or category, discrete value)\n",
    "            - binary classification (2 classes)\n",
    "            - multi-class classification (more than 2 classes)\n",
    "        - regression (predict continuous value)\n",
    "2. Unsupervised (deductive) learning\n",
    "    - given training data, no desired outputs\n",
    "    - learn a function that describes hidden structure from unlabeled data\n",
    "3. Semi-supervised learning\n",
    "    - given training data, some desired outputs\n",
    "    - learn a function that maps inputs to outputs\n",
    "4. Reinforcement learning\n",
    "    - rewards from sequence of actions\n",
    "    - learn a function that maximizes a reward signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 2\n",
    "\n",
    "### Data\n",
    "data properties:\n",
    "- value : how useful the data is for the problem\n",
    "- volume : how much data to be analyzed and processed\n",
    "- variety : what types of data (structured, unstructured, semi-structured)\n",
    "- velocity : how fast data is generated and processed\n",
    "- veracity : how accurate and reliable the data is\n",
    "\n",
    "#### Data quality\n",
    "Have to check:\n",
    "- accuracy : should reflect reality\n",
    "- completeness : should have all the required data\n",
    "- consistency : should be consistent with other data\n",
    "- validity : should be valid according to the domain\n",
    "- uniqueness : should be unique, no duplications or redundancies\n",
    "- timeliness : should be up-to-date\n",
    "\n",
    "Issues might be:\n",
    "- missing values\n",
    "    - data not collected\n",
    "    - variable not applicable for that observation\n",
    "- outliers \n",
    "    - data point that differs significantly from other observations\n",
    "- inconsistent data\n",
    "- invalid data\n",
    "    - can be due to:\n",
    "        - measurement error\n",
    "        - experimental error\n",
    "        - data corruption\n",
    "        - data entry error\n",
    "        - natural variation\n",
    "- noise\n",
    "    - extraneous object, modification, or event that interferes with the data\n",
    "- duplicate data\n",
    "    - when merging data from heterogeneous sources\n",
    "- biased / unrepresentative data\n",
    "\n",
    "#### Data types\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "\n",
    "- linear regression can be used to fit a model to an observed dataset of values of the response (dependent variable) and explanatory variables (independent variables / features)\n",
    "- $x^{(i)}$ is the vector of input variables / features, $x^{(i)} = \\begin{bmatrix} x_0^{(i)} \\\\ x_1^{(i)} \\\\ \\vdots \\\\ x_n^{(i)} \\end{bmatrix} _{((n+1) \\times 1)}$, where $n$ is the number of features, with $x_0^{(i)} = 1$ being the intercept term. \n",
    "- $y^{(i)}$ is the output variable / target.\n",
    "- $(x^{(i)}, y^{(i)})$ is a training example.\n",
    "- $\\{(x^{(i)}, y^{(i)}) : i = 1 \\dotsm m\\}$ is the training set, where $m$ is the number of examples in the training set.\n",
    "\n",
    "Goal : to learn a function $h(x) : \\text{space of input values} \\rightarrow \\text{space of output values}$, so that $h(x)$ is a good predictor for the corresponding value $y$\n",
    "\n",
    "#### Equations\n",
    "\n",
    "If we decide to approximate $y$ as a linear function of $x$, then for the $i^{th}$ training example:\n",
    "\n",
    "$$\\hat{y}^{(i)} =  h_\\theta(x^{(i)}) = \\theta_0 + \\theta_1 x^{(i)}_1 + \\theta_2 x^{(i)}_2 + \\dotsm + \\theta_n x^{(i)}_n = \\sum_{j=0}^n \\theta_j x^{(i)}_j$$\n",
    "\n",
    "This is called **simple / univariate** linear regression for $n = 1$, and **multiple** linear regression, (if $n > 1$). This is different from **multivariate** regression, which pertains to multiple dependent variables and multiple independent variables. [Link](https://stats.stackexchange.com/q/2358/331716)\n",
    "\n",
    "Then we can define the cost function as:\n",
    "$$J(\\theta) = \\frac{1}{2m} \\sum_{i=1}^m (h_\\theta(x^{(i)}) - y^{(i)})^2$$\n",
    "\n",
    "This is the **ordinary least squares (OLS)** cost function, working to minimize the **mean squares error (MSE)**.\n",
    "\n",
    "Goal : to choose $\\theta$ so as to minimize $J(\\theta)$\n",
    "\n",
    "#### Vectorized\n",
    "\n",
    "$$ X = \\begin{bmatrix} - \\left( x^{(1)} \\right)^T - \\\\ - \\left( x^{(2)} \\right)^T - \\\\ \\vdots \\\\ - \\left( x^{(m)} \\right)^T - \\end{bmatrix}_{(m \\times (n+1))} , \\qquad \\theta = \\begin{bmatrix} \\theta_0 \\\\ \\theta_1 \\\\ \\vdots \\\\ \\theta_n \\end{bmatrix}_{((n+1) \\times 1)} \\qquad and \\qquad y = \\begin{bmatrix} y^{(1)} \\\\ y^{(2)} \\\\ \\vdots \\\\ y^{(m)} \\end{bmatrix} _{(m \\times 1)}$$\n",
    "\n",
    "Then the vector of predictions, \n",
    "\n",
    "$$ \\hat{y} =  X\\theta = \\begin{bmatrix} - \\left( x^{(1)} \\right)^T\\theta - \\\\ - \\left( x^{(2)} \\right)^T\\theta - \\\\ \\vdots \\\\ - \\left( x^{(m)} \\right)^T\\theta - \\end{bmatrix}_{(m \\times 1)} $$\n",
    "\n",
    "We can rewrite the least-squares cost as following, replacing the explicit sum by matrix multiplication:\n",
    "\n",
    "$$J(\\theta) = \\frac{1}{2m} (X\\theta - y)^T(X\\theta - y)$$\n",
    "\n",
    "#### Finding coefficients for simple linear regression\n",
    "\n",
    "The simple linear regression model is $y = \\theta_0 + \\theta_1 x$, where $\\theta_0$ is the intercept and $\\theta_1$ is the slope. The coefficients are found by minimizing the sum of squared residuals (SSR), which is the sum of the squares of the differences between the observed dependent variable ($y$) and those predicted by the linear function ($\\hat{y}$).\n",
    "\n",
    "Make a table with $x_i$, $y_i$, $x_i - \\bar{x}$, $y_i - \\bar{y}$, $(x_i - \\bar{x})^2$, $(x_i - \\bar{x})(y_i - \\bar{y})$.\n",
    "\n",
    "Equation for $\\theta_1$: $$\\theta_1 = \\frac{\\sum_{i=1}^m (x^{(i)} - \\bar{x})(y^{(i)} - \\bar{y})}{\\sum_{i=1}^m (x^{(i)} - \\bar{x})^2}$$\n",
    "Equation for $\\theta_0$: $$\\theta_0 = \\bar{y} - \\theta_1 \\bar{x} $$\n",
    "\n",
    "#### Assumptions for linear regression\n",
    "1. dependent and independent variables are linearly related\n",
    "2. independent variables are not random\n",
    "3. residuals are normally distributed\n",
    "4. residuals are homoscedastic (constant variance)\n",
    "\n",
    "### Polynomial Regression\n",
    "\n",
    "Polynomial regression is a form of regression analysis in which the relationship between the independent variable $x$ and the dependent variable $y$ is modelled as an $n^{th}$ degree polynomial in $x$. Polynomial regression fits a nonlinear relationship between the value of $x$ and $y$.\n",
    "- Simplest form of polynomial regression is a quadratic equation, $y = \\theta_0 + \\theta_1 x + \\theta_2 x^2$\n",
    "\n",
    "### Normal Equation\n",
    "\n",
    "The normal equation is an analytical solution to the linear regression problem with a ordinary least square cost function. That is, to find the value of $\\theta$ that minimizes $J({\\theta})$, take the [gradient](https://mathinsight.org/gradient_vector) of $J(\\theta)$ with respect to $\\theta$ and equate to $0$, ie $\\nabla_\\theta J(\\theta) = 0$.\n",
    "\n",
    "Solving for $\\theta$, we get \n",
    "\n",
    "$$\\theta = (X^TX)^{-1} X^Ty$$\n",
    "\n",
    "[Here](https://eli.thegreenplace.net/2014/derivation-of-the-normal-equation-for-linear-regression/) is a post containing the derivation of the normal equation.\n",
    "\n",
    "### Gradient Descent\n",
    "\n",
    "Gradient descent is based on the observation that if the function $J({\\theta})$ is differentiable in a neighborhood of a point $\\theta$, then $J({\\theta})$ decreases fastest if one goes from $\\theta$ in the direction of the negative gradient of $J({\\theta})$ at $\\theta$. \n",
    "\n",
    "Thus if we repeatedly apply the following update rule, ${\\theta := \\theta - \\alpha \\nabla J(\\theta)}$ for a sufficiently small value of **learning rate**, $\\alpha$, we will eventually converge to a value of $\\theta$ that minimizes $J({\\theta})$.\n",
    "\n",
    "For a specific paramter $\\theta_j$, the update rule is \n",
    "\n",
    "$$\\theta_j := \\theta_j - \\alpha \\frac{\\partial}{\\partial \\theta_j} J({\\theta}) $$\n",
    "\n",
    "Using the definition of $J({\\theta})$, we get\n",
    "\n",
    "$$\\frac{\\partial}{\\partial \\theta_j} J({\\theta}) = \\sum_{i=1}^m (h_\\theta(x^{(i)}) - y^{(i)})x_j^{(i)}$$\n",
    "\n",
    "Therefore, we repeatedly apply the following update rule:\n",
    "\n",
    "$\\qquad Loop \\: \\{$\n",
    "    $\\qquad \\qquad \\theta_j := \\theta_j - \\alpha \\frac{1}{m} \\sum_{i=1}^m \\left( h_\\theta(x^{(i)}) - y^{(i)}\\right)x_j^{(i)} \\qquad \\text{simultaneously update } \\theta_j \\text{ for all } j$\n",
    "$\\qquad \\}$\n",
    "\n",
    "This method looks at every example in the entire training set on every step, and is called **batch gradient descent (BGD)**. \n",
    "\n",
    "When the cost function $J$ is convex, all local minima are also global minima, so in this case gradient descent can converge to the global solution.\n",
    "\n",
    "There is an alternative to BGD that also works very well:\n",
    "\n",
    "$\\qquad Loop \\: \\{$\n",
    "    $\\qquad \\qquad for \\: i=1 \\: to \\: m \\: \\{$\n",
    "    $\\qquad \\qquad \\qquad \\theta_j := \\theta_j - \\alpha \\left( h_\\theta(x^{(i)}) - y^{(i)}\\right)x_j^{(i)} \\qquad \\text{simultaneously update } \\theta_j \\text{ for all } j$\n",
    "    $\\qquad \\qquad \\}$\n",
    "$\\qquad \\}$\n",
    "\n",
    "This is **stochastic gradient descent (SGD)** (also incremental gradient descent), where we repeatedly run through the training set, and for each training example, we update the parameters using gradient of the error for that training example only.\n",
    "\n",
    "Whereas BGD has to scan the entire training set before taking a single step, SGD can start making progress right away with each example it looks at. \n",
    "\n",
    "Often, SGD gets $\\theta$ *close* to the minimum much faster than BGD. However it may never *converge* to the minimum, and $\\theta$ will keep oscillating around the minimum of $J(\\theta)$; but in practice these values are reasonably good approximations. Also, by slowly decreasing $\\alpha$ to $0$ as the algorithm runs, $\\theta$ converges to the global minimum rather than oscillating around it.\n",
    "\n",
    "#### Underfitting and Overfitting\n",
    "\n",
    "Error(model) = Bias(model) + Variance(model) + Irreducible Error\n",
    "\n",
    "Bias : how far off in general the model is from the actual value. High bias means the model is not complex enough to capture the underlying trend of the data. Low bias means the model is complex enough to capture the underlying trend of the data.\n",
    "\n",
    "Variance : how much the model changes based on the training data. High variance means the model changes a lot based on the training data. Low variance means the model does not change much based on the training data.\n",
    "\n",
    "**Underfitting** – High bias and low variance\n",
    "- model does not fit the training data and does not generalize well to unseen data\n",
    "\n",
    "Techniques to reduce underfitting :\n",
    "1. Increase model complexity\n",
    "2. Increase number of features, performing feature engineering\n",
    "3. Remove noise from the data.\n",
    "4. Increase the number of epochs or increase the duration of training to get better results.\n",
    "\n",
    "**Overfitting** – High variance and low bias\n",
    "- model fits the training data well, but does not generalize well to unseen data\n",
    "\n",
    "Techniques to reduce overfitting :\n",
    "1. Increase training data (data augmentation)\n",
    "2. Reduce model complexity.\n",
    "3. Early stopping during the training phase (have an eye over the loss over the training period as soon as loss begins to increase stop training).\n",
    "4. Ridge Regularization and Lasso Regularization\n",
    "5. Use dropout for neural networks to tackle overfitting.\n",
    "6. Ensemble learning (bagging, boosting, stacking)\n",
    "7. Cross-validation, holdout validation, k-fold cross-validation\n",
    "\n",
    "<img src=\"https://i.imgur.com/b4CWHHf.png\" width=\"500\" style=\"display: block; margin-left: auto; margin-right: auto;\">\n",
    "\n",
    "Simple models like linear and logistic regression are prone to underfitting, whereas complex models like decision trees and neural networks are prone to overfitting.\n",
    "\n",
    "\n",
    "### Adding regularization\n",
    "\n",
    "Regularization is a technique to reduce overfitting in machine learning. This technique discourages learning a more complex or flexible model, by shrinking the parameters towards $0$.\n",
    "\n",
    "We can regularize machine learning methods through the cost function using $L1$ regularization or $L2$ regularization. $L1$ regularization adds an absolute penalty term to the cost function, while $L2$ regularization adds a squared penalty term to the cost function. A model with $L1$ norm for regularisation is called **lasso regression**, and one with (squared) $L2$ norm for regularisation is called **ridge regression**. [Link](https://towardsdatascience.com/intuitions-on-l1-and-l2-regularisation-235f2db4c261)\n",
    "\n",
    "$$J(\\theta)_{L1} = \\frac{1}{2m} \\left( \\sum_{i=1}^m \\left( h_\\theta\\left( x^{(i)} \\right) - y^{(i)} \\right)^2 \\right) + \\frac{\\lambda}{2m} \\left( \\sum_{j=1}^n |\\theta_j| \\right)$$\n",
    "\n",
    "$$J(\\theta)_{L2} = \\frac{1}{2m} \\left( \\sum_{i=1}^m \\left( h_\\theta\\left( x^{(i)} \\right) - y^{(i)} \\right)^2 \\right) + \\frac{\\lambda}{2m} \\left( \\sum_{j=1}^n \\theta_j^2 \\right)$$\n",
    "\n",
    "The partial derivative of the cost function for lasso linear regression is:\n",
    "\n",
    "\\begin{align}\n",
    "& \\frac{\\partial J(\\theta)_{L1}}{\\partial \\theta_0} = \\frac{1}{m} \\sum_{i=1}^m \\left( h_\\theta \\left(x^{(i)} \\right) - y^{(i)} \\right) x_j^{(i)} \n",
    "& \\qquad \\text{for } j = 0 \\\\\n",
    "& \\frac{\\partial J(\\theta)_{L1}}{\\partial \\theta_j} = \\frac{1}{m} \\sum_{i=1}^m \\left( h_\\theta \\left( x^{(i)} \\right) - y^{(i)} \\right) x_j^{(i)} + \\frac{\\lambda}{2m} signum (\\theta_j)\n",
    "& \\qquad \\text{for } j \\ge 1\n",
    "\\end{align}\n",
    "\n",
    "Similarly for ridge linear regression,\n",
    "\n",
    "\\begin{align}\n",
    "& \\frac{\\partial J(\\theta)_{L2}}{\\partial \\theta_0} = \\frac{1}{m} \\sum_{i=1}^m \\left( h_\\theta \\left(x^{(i)} \\right) - y^{(i)} \\right) x_j^{(i)} \n",
    "& \\qquad \\text{for } j = 0 \\\\\n",
    "& \\frac{\\partial J(\\theta)_{L2}}{\\partial \\theta_j} = \\frac{1}{m} \\sum_{i=1}^m \\left( h_\\theta \\left( x^{(i)} \\right) - y^{(i)} \\right) x_j^{(i)} + \\frac{\\lambda}{m} \\theta_j \n",
    "& \\qquad \\text{for } j \\ge 1\n",
    "\\end{align}\n",
    "\n",
    "These equations can be substituted into the general gradient descent update rule to get the specific lasso / ridge update rules.\n",
    "\n",
    "Elastic Net regression is a combination of lasso and ridge regression. It's regularization term is a combination of the $L1$ and $L2$ regularization terms. The cost function is:\n",
    "$$ J(\\theta)_{ElasticNet} = \\frac{1}{2m} \\left( \\sum_{i=1}^m \\left( h_\\theta\\left( x^{(i)} \\right) - y^{(i)} \\right)^2 \\right) + \\frac{\\lambda_1}{2m} \\left( \\sum_{j=1}^n |\\theta_j| \\right) + \\frac{\\lambda_2}{2m} \\left( \\sum_{j=1}^n \\theta_j^2 \\right)$$\n",
    "\n",
    "#### Note:\n",
    "- $\\theta_0$ is NOT constrained\n",
    "- scale the data before using Ridge regression\n",
    "- $\\lambda$ is a hyperparameter: bigger results in flatter and smoother model \n",
    "- Lasso tends to completely eliminate the weights of the least important features (i.e., setting them to 0) and it automatically performs feature selection\n",
    "- Last way to constrain the weights is Elastic net, a combination of Ridge and Lasso\n",
    "- When to use which?\n",
    "    * Ridge is a good default\n",
    "    * If you suspect some features are not useful, use Lasso or Elastic\n",
    "    * When features are more than training examples, prefer Elastic\n",
    "\n",
    "### Metrics for evaluating regression models\n",
    "1. Mean Absolute Error (MAE)\n",
    "    - average of absolute differences between predictions and actual values\n",
    "    - robust to outliers, does not penalize large errors like MSE, not differentiable at 0\n",
    "    - $$ MAE = \\frac{1}{m} \\sum_{i=1}^m |y^{(i)} - \\hat{y}^{(i)}| $$\n",
    "2. Mean Squared Error (MSE)\n",
    "    - average of squared differences between predictions and actual values\n",
    "    - penalizes large errors more than MAE, more sensitive to outliers, differentiable\n",
    "    - $$ MSE = \\frac{1}{m} \\sum_{i=1}^m (y^{(i)} - \\hat{y}^{(i)})^2 $$\n",
    "3. Mean Absolute Percentage Error (MAPE)\n",
    "    - average of absolute percentage differences between predictions and actual values\n",
    "    - $$ MAPE = \\frac{1}{m} \\sum_{i=1}^m \\left| \\frac{y^{(i)} - \\hat{y}^{(i)}}{y^{(i)}} \\right| $$\n",
    "4. Root Mean Squared Error (RMSE)\n",
    "    - square root of MSE\n",
    "    - $$ RMSE = \\sqrt{\\frac{1}{m} \\sum_{i=1}^m (y^{(i)} - \\hat{y}^{(i)})^2} $$\n",
    "5. R-squared\n",
    "    - proportion of variance in the dependent variable that is predictable from the independent variable(s)\n",
    "    - $$ R^2 = 1 - \\frac{\\sum_{i=1}^m (y^{(i)} - \\hat{y}^{(i)})^2}{\\sum_{i=1}^m (y^{(i)} - \\bar{y})^2} $$\n",
    "    - value varies between 0 and 1 usually, where 0 indicates that the model explains none of the variability of the response data around its mean, and 1 indicates that the model explains all the variability of the response data around its mean\n",
    "    - if you have negative $R^2$, it means that your model is worse than the mean model\n",
    "    - tends to increase when more predictors are added to the model, even if they are unrelated to the response\n",
    "        - this could be misleading, because the model may not actually have a better fit\n",
    "6. Adjusted R-squared\n",
    "    - penalizes the addition of unnecessary predictors to the model\n",
    "    - $$ R^2_{adj} = 1 - \\frac{(1 - R^2)(n - 1)}{n - k - 1} $$\n",
    "    - where $n$ is the number of observations and $k$ is the number of predictors\n",
    "    - $R^2_{adj}$ increases only when the increase in $R^2$ is more than what is expected to happen by chance\n",
    "    - $R^2_{adj}$ decreases when the model contains useless predictors\n",
    "    - $R^2_{adj}$ can be negative, and it is always less than or equal to $R^2$\n",
    "\n",
    "The metrics with squared errors (MSE, RMSE) are more commonly used than MAE and MAPE, because they are differentiable and penalize large errors more. RMSE is the most popular metric, because it is interpretable in the \"y\" units.\n",
    "\n",
    "### Cross-validation\n",
    "\n",
    "Cross-validation is a technique for evaluating ML models by training several ML models on subsets of the available input data and evaluating them on the complementary subset of the data. Types:\n",
    "1. holdout validation set approach\n",
    "    - split the data into training and validation sets\n",
    "    - train the model on the training set\n",
    "    - evaluate the model on the validation set\n",
    "2. leave-p-out cross-validation\n",
    "    - split the data into training and testing sets (with $p$ observations in the testing set)\n",
    "    - repeat the above steps with different splits of the data, average the metric with different p-size testing sets\n",
    "3. k-fold cross-validation\n",
    "    - split the data into $k$ folds\n",
    "    - for each fold, train the model on the remaining $k-1$ folds and evaluate it on the current fold\n",
    "    - average the metric with different folds\n",
    "4. stratified k-fold cross-validation\n",
    "    - same as k-fold cross-validation, but the folds are made by preserving the percentage of samples for each class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basis functions\n",
    "\n",
    "Simplest model for linear regression is given by $y(\\bf{x}, \\bf{w}) = w_0 + w_1 x_1 + \\dotsm + w_D x_D$\n",
    "- key property of this model is that it is a linear function of the parameters $w_0, \\dotsm, w_D$\n",
    "- basis functions can be used to extend linear models to make them non-linear\n",
    "- basis functions are fixed and known functions of the input variables\n",
    "- the model is still linear in the parameters, but non-linear in the input variables $$ y(\\bf{x}, \\bf{w}) = w_0 + \\sum_{j=1}^M w_j \\phi_j(\\bf{x}) $$ where $\\phi_j(\\bf{x})$ are the basis functions\n",
    "- using linear combinations of fixed nonlinear functions of the input variables, we can model a wide range of nonlinear functions\n",
    "- examples of basis functions:\n",
    "    - polynomial basis functions $$ \\phi_j(x) = x^j $$\n",
    "    - Gaussian basis functions $$ \\phi_j(x) = exp \\left\\{ - \\frac{(x - \\mu_j)^2}{2s^2} \\right\\} $$\n",
    "    - sigmoidal basis functions $$ \\phi_j(x) = \\sigma \\left( \\frac{x - \\mu_j}{s} \\right) $$ where $\\sigma(a) = \\frac{1}{1 + exp(-a)}$ is the logistic sigmoid function\n",
    "- advantages of basis functions:\n",
    "    - closed-form solution for the parameters\n",
    "    - non linear models mapping input variables to output variables through basis functions\n",
    "- disadvantages:\n",
    "    - assumption that the basis functions are fixed and not learned\n",
    "    - curse of dimensionality, to capture the input space with a fine grid of basis functions, the number of basis functions grows exponentially with the number of input variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminative classifiers\n",
    "\n",
    "### Generative vs Discriminative classifiers\n",
    "\n",
    "| Aspect                     | Discriminative Models                         | Generative Models                            |\n",
    "|----------------------------|----------------------------------------------|---------------------------------------------|\n",
    "| Objective                  | Focuses on learning the decision boundary that separates different classes or categories in the data. | Focuses on modeling the joint distribution of features and labels to generate new data samples. |\n",
    "| Modeling Approach          | Directly models the conditional probability of the class labels given the features (P(y\\|x)). | Models the joint probability of both class labels and features (P(x, y)). |\n",
    "| Use Case                   | Well-suited for classification tasks where the primary goal is to predict the class labels of new data points. | Suitable for classification tasks and can also be used for data generation and sampling. |\n",
    "| Data Generation            | Cannot be used for generating new data samples as it only models the decision boundary. | Can be used to generate new data samples by sampling from the learned joint distribution. |\n",
    "| Training Data              | Requires labeled data for learning the conditional probabilities. | Requires both labeled data for estimating class priors and conditional probabilities. |\n",
    "| Dimensionality Reduction   | Not well-suited for dimensionality reduction tasks. | Can be used for dimensionality reduction tasks, such as generating low-dimensional representations of data. |\n",
    "| Example Algorithms         | Logistic Regression, Support Vector Machines (SVM), Neural Networks (for classification). | Naive Bayes, Gaussian Mixture Models, Hidden Markov Models. |\n",
    "\n",
    "\n",
    "Types of classifiers:\n",
    "1. Linear classifiers\n",
    "    - classes are seperated by a linear decision boundary, if for a given input $x$, $\\theta^Tx \\ge 0$ then $y = 1$, else $y = 0$\n",
    "    - $\\theta$'s are learned from the training data during the training phase, then used to classify new data\n",
    "    - examples:\n",
    "        - logistic regression\n",
    "        - support vector machines\n",
    "2. Non-linear classifiers\n",
    "    - classes are seperated by a non-linear decision boundary\n",
    "    - examples:\n",
    "        - Decision trees\n",
    "        - Random forests\n",
    "        - Neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "- transforms the output of a linear regression model into a probability by applying the logistic function (sigmoid function) $$ \\sigma(z) = \\frac{1}{1 + e^{-z}} $$\n",
    "- the output of the logistic function is interpreted as the probability of the input belonging to the positive class, $$ h_{\\theta}(x) = P(y = 1 \\mid x) = \\sigma(\\theta^Tx) = \\frac{1}{1 + e^{-\\theta^Tx}} $$\n",
    "    - if $\\theta^Tx = 0$, then $P(y = 1 \\mid x) = 0.5$\n",
    "    - if $\\theta^Tx \\gg 0$, then $P(y = 1 \\mid x) \\approx 1$\n",
    "    - if $\\theta^Tx \\ll 0$, then $P(y = 1 \\mid x) \\approx 0$\n",
    "    - here $f(x) = \\theta^Tx$ is called logit function\n",
    "- works by determining the weights $\\theta$ such that the predicted probability is maximized for the positive class and minimized for the negative class\n",
    "- you maximize the log-likelihood function, $$ \\ell(\\theta) = \\sum_{i=1}^m y^{(i)} \\log P(y^{(i)} = 1 \\mid x^{(i)}) + (1 - y^{(i)}) \\log P(y^{(i)} = 0 \\mid x^{(i)}) $$ \n",
    "    - if $y^{(i)} = 1$, then $P(y^{(i)} = 1 \\mid x^{(i)})$ is maximized, which happens when $\\theta^Tx^{(i)}$ is maximized\n",
    "    - if $y^{(i)} = 0$, then $P(y^{(i)} = 0 \\mid x^{(i)})$ is maximized, which happens when $\\theta^Tx^{(i)}$ is minimized\n",
    "- this method is called maximum likelihood estimation (MLE)\n",
    "- Logit function\n",
    "    - the logit function is the inverse of the logistic function, $$ \\text{logit}(p) = \\log \\left( \\frac{p}{1 - p} \\right) = \\sigma^{-1}(p) $$\n",
    "    - because of this, logit is also called log-odds, because it is the logarithm of the odds, $$ \\text{odds}(p) = \\frac{p}{1 - p} $$\n",
    "- dependent variable follows Bernoulli distribution\n",
    "- cost function is $$ J(\\theta) = - \\frac{1}{m} \\sum_{i=1}^m y^{(i)} \\log P(y^{(i)} = 1 \\mid x^{(i)}) + (1 - y^{(i)}) \\log P(y^{(i)} = 0 \\mid x^{(i)}) $$\n",
    "- gradient descent update rule is $$ \\theta_j := \\theta_j - \\alpha \\frac{1}{m} \\sum_{i=1}^m \\left( h_\\theta(x^{(i)}) - y^{(i)}\\right)x_j^{(i)} \\qquad \\text{for } j \\ge 1 $$ but here the hypothesis function is different from that of linear regression, as defined above\n",
    "- regularized cost functions are exactly the same as in linear regression\n",
    "    - L1 regularization : $$ J(\\theta)_{L1} = \\frac{1}{2m} \\left( \\sum_{i=1}^m \\left( h_\\theta\\left( x^{(i)} \\right) - y^{(i)} \\right)^2 \\right) + \\frac{\\lambda}{2m} \\left( \\sum_{j=1}^n |\\theta_j| \\right) $$\n",
    "    - L2 regularization : $$ J(\\theta)_{L2} = \\frac{1}{2m} \\left( \\sum_{i=1}^m \\left( h_\\theta\\left( x^{(i)} \\right) - y^{(i)} \\right)^2 \\right) + \\frac{\\lambda}{2m} \\left( \\sum_{j=1}^n \\theta_j^2 \\right) $$\n",
    "\n",
    "### Types of logistic regression\n",
    "1. Binary logistic regression\n",
    "    - the dependent variable has only two possible outcomes\n",
    "    - the goal is to determine the probability that an observation is in a particular category\n",
    "2. Multinomial logistic regression\n",
    "    - the dependent variable has three or more unordered categories\n",
    "    - the goal is to determine the probability that an observation is in each category\n",
    "3. Ordinal logistic regression\n",
    "    - the dependent variable has three or more ordered categories\n",
    "    - the goal is to determine the probability that an observation is in each category\n",
    "\n",
    "### Metrics for evaluating classification models\n",
    "\n",
    "Confusion Matrix:\n",
    "<img src=\"https://i.imgur.com/v4FpYTm.png\" width=\"400\" style=\"display: block; margin-left: auto; margin-right: auto;\">\n",
    "\n",
    "Accuracy = $\\frac{TP + TN}{TP + TN + FP + FN}$\n",
    "\n",
    "Error Rate = $\\frac{FP + FN}{TP + TN + FP + FN} = 1 - Accuracy$\n",
    "\n",
    "Precision = $\\frac{TP}{TP + FP}$\n",
    "\n",
    "Recall / Sensitivity / TPR = $\\frac{TP}{TP + FN}$\n",
    "\n",
    "TNR / Specificity = $\\frac{TN}{TN + FP}$\n",
    "\n",
    "FPR / Fall-out / Type I error = $\\frac{FP}{FP + TN} = 1 - TNR$\n",
    "\n",
    "Type II error / False Negative Rate = $\\frac{FN}{TP + FN} = 1 - Recall$\n",
    "\n",
    "F1 Score = $\\frac{2 * Precision * Recall}{Precision + Recall}$\n",
    "\n",
    "#### ROC Curve\n",
    "\n",
    "AUC = Area Under the ROC Curve : ROC Curves are used to see how well your classifier can separate positive and negative examples and to identify the best threshold for separating them. To be able to use the ROC curve, your classifier has to be ranking - that is, it should be able to rank examples such that the ones with higher rank are more likely to be positive.\n",
    "- y axis : TPR\n",
    "- x axis : FPR\n",
    "\n",
    "<img src=\"https://i.imgur.com/FICMCrT.png\" width=\"600\" style=\"display: block; margin-left: auto; margin-right: auto;\">\n",
    "\n",
    "Given a dataset and a classifier, you can plot the ROC curve by doing the following:\n",
    "1. Rank the examples according to the classifier's output, from highest to lowest.\n",
    "2. Start at (0,0).\n",
    "3. For each example in the dataset:\n",
    "    - If the example is positive, move $1/positive\\_examples$ up.\n",
    "    - If the example is negative, move $1/negative\\_examples$ to the right.\n",
    "4. The resulting curve is the ROC curve.\n",
    "\n",
    "<src img=\"https://habrastorage.org/files/267/36b/ff1/26736bff158a4d82893ff85b2022cc5b.gif\" width=\"300\" style=\"display: block; margin-left: auto; margin-right: auto;\">\n",
    "\n",
    "AUC provides an aggregate measure of performance across all possible classification thresholds. One way of interpreting AUC is as the probability that the model ranks a random positive example more highly than a random negative example.\n",
    "\n",
    "AUC is desirable for these two reasons:\n",
    "- scale-invariant : measures how well predictions are ranked, rather than their absolute values.\n",
    "- classification-threshold-invariant : measures the quality of the model’s predictions irrespective of classification threshold\n",
    "\n",
    "Caveats, which limit usefulness of AUC in certain cases:\n",
    "- scale-invariance : sometimes we really do need well calibrated probability outputs\n",
    "- classification-threshold invariance : cases where there are wide disparities in the cost of false negatives vs. false positives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees\n",
    "Advantages:\n",
    "- inexpensive to construct\n",
    "- extremely fast at classifying unknown records\n",
    "- easy to interpret for small-sized trees\n",
    "- can easily handle redundant or irrelevant attributes (unless the attributes are interacting)\n",
    "\n",
    "Disadvantages:\n",
    "- space of possible decision trees is exponentially large\n",
    "- greedy approaches are often unable to find the best tree\n",
    "- does not take into account interactions between attributes\n",
    "- each decision boundary involves only a single attribute\n",
    "\n",
    "#### Decision tree impurity measures\n",
    "\n",
    "$${\\displaystyle \\text{Entropy}(t) = -\\sum_{c=1}^{C} p(c|t) log_2(p(c|t))}$$\n",
    "\n",
    "$${\\displaystyle Gini(t) = 1 - \\sum_{c=1}^{C} [p(c|t)]^2}$$\n",
    "\n",
    "$$\\text{Misclassification error}(t) =  1 - \\max_c[p(c|t)]$$\n",
    "\n",
    "Where $t$ is the current node, $C$ is the number of classes, and $p(c|t)$ is the proportion of the samples that belong to class $c$ at node $t$.\n",
    "\n",
    "<img src=\"https://i.imgur.com/0Zn675n.png\" width=\"400\" style=\"display: block; margin-left: auto; margin-right: auto;\">\n",
    "\n",
    "### Using information gain to decide split\n",
    "1. Calculate the entropy of the target. $$ \\text{Entropy}(S) = - \\sum_{i=1}^n p_i \\log_2 p_i $$\n",
    "2. Calculate the entropy of the target for each feature. $$ \\text{Entropy}(S, A) = \\sum_{i=1}^n \\frac{|S_i|}{|S|} \\text{Entropy}(S_i) $$ where $S_i$ is the subset of $S$ for which feature $A$ has value $i$. $$ \\text{Entropy}(S_i) = - \\sum_{i=1}^n p_i \\log_2 p_i $$\n",
    "3. Calculate the information gain for each feature. $$ \\text{Information Gain}(S, A) = \\text{Entropy}(S) - \\text{Entropy}(S, A) $$\n",
    "4. Choose the feature with the highest information gain.\n",
    "\n",
    "### Using Gini index to decide split\n",
    "1. Calculate the Gini index of the target. $$ \\text{Gini}(S) = 1 - \\sum_{i=1}^n p_i^2 $$\n",
    "2. Calculate the Gini index of the target for each feature. $$ \\text{Gini}(S, A) = \\sum_{i=1}^n \\frac{|S_i|}{|S|} \\text{Gini}(S_i) $$ where $S_i$ is the subset of $S$ for which feature $A$ has value $i$. $$ \\text{Gini}(S_i) = 1 - \\sum_{i=1}^n p_i^2 $$\n",
    "3. Calculate the information gain for each feature. $$ \\text{Gini Gain}(S, A) = \\text{Gini}(S) - \\text{Gini}(S, A) $$\n",
    "4. Choose the feature with the highest gini gain.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instance based learning\n",
    "\n",
    "- systems that learn the training examples by heart and then generalizes to new instances based on some similarity measure\n",
    "- called instance-based because it builds the hypotheses from the training instances\n",
    "- also called lazy learning, memory-based learning, or case-based reasoning\n",
    "- time complexity is $O(n)$ where $n$ is the number of training instances\n",
    "\n",
    "### k-Nearest Neighbors (kNN) \n",
    "- non-parametric method, supervised learning\n",
    "- used for classification\n",
    "    - object is classified by a majority vote of its $k$ nearest neighbors\n",
    "    - if $k=1$, then the object is simply assigned to the class of that single nearest neighbor\n",
    "- used for regression\n",
    "    - object's value is estimated by the average of its $k$ nearest neighbors\n",
    "- $k$ is a hyperparameter that is usually chosen by cross-validation\n",
    "- kNN is sensitive to the local structure of the data\n",
    "    - if the data is not uniformly sampled, then the nearest neighbors will not be representative of the entire data set\n",
    "    - in this case, the decision boundary will be irregular\n",
    "- kNN is sensitive to the distance metric used (Euclidean, Manhattan, Minowski, etc.)\n",
    "- drawback when class distribution is skewed\n",
    "    - if one class is much more frequent than the others, then the nearest neighbors will be dominated by the most frequent class\n",
    "    - solution: use weighted voting, where the weights are the inverse of the distance to the query point\n",
    "\n",
    "### Locally Weighted Regression (LWR)\n",
    "- memory-based method that performs a regression around a point of interest using only training data that are local to that point\n",
    "- non-parametric method (parameters are computed individually for each query point)\n",
    "- cost function is modified as $$J(\\theta) = \\frac{1}{2m} \\sum_{i=1}^m w^{(i)} (h_\\theta(x^{(i)}) - y^{(i)})^2$$ where $w^{(i)} = \\exp \\left( - \\frac{(x^{(i)} - x)^2}{2\\tau^2} \\right)$ and $\\tau$ is the bandwidth parameter that controls the degree of smoothing\n",
    "    - if $(x^{(i)} - x)^2$ is small, then $w^{(i)}$ is close to 1, and vice versa\n",
    "- training data must be available at the time of prediction\n",
    "\n",
    "### Kernel function\n",
    "- for linear regression, the hypothesis is $h_\\theta(x) = \\theta^T x$, the dot product is integral to the prediction operation\n",
    "- suppose the vectors are not linearly separable, then we can use a function $\\phi(x)$ to map the vectors to a higher dimensional space where they are linearly separable\n",
    "- kernel function is a function that maps a function of the vectors in the original space to a dot product of the vectors in a higher dimensional space\n",
    "- Let $\\phi(x) : \\mathbb{R}^2 \\rightarrow \\mathbb{R}^3$ be a function that maps $x$ from 2D to 3D space, and the kernel function is defined as $K(x, x^*) = \\phi(x) \\cdot \\phi(x^*)$\n",
    "- Consider $x = [x_1, x_2]$,  $x^* = [x^*_1, x^*_2]$, then $\\phi(x) = [x_1^2, \\sqrt{2}x_1x_2, x_2^2]$ and $\\phi(x^*) = [x_1^{*2}, \\sqrt{2}x_1^*x_2^*, x_2^{*2}]$\n",
    "- Here $\\phi(x) \\cdot \\phi(x^*) = x_1^2x_1^{*2} + 2x_1x_2x_1^*x_2^* + x_2^2x_2^{*2} = (x_1x_1^* + x_2x_2^*)^2 = (x \\cdot x^*)^2$\n",
    "- So $K(x, x^*) = (x \\cdot x^*)^2$ is a kernel function, and we were able to perform the dot product in a higher dimensional space without explicitly computing $\\phi(x)$ and $\\phi(x^*)$, which is computationally expensive operation\n",
    "- $x \\rightarrow \\phi(x)$, $x^* \\rightarrow \\phi(x^*)$, then $x \\cdot x^* \\rightarrow K(x, x^*) = \\phi(x) \\cdot \\phi(x^*)$\n",
    "\n",
    "### Radial Basis Functions (RBF) \n",
    "- The basic idea behind RBFs is to model the data using a set of basis functions, where each basis function represents a localized influence on the data.\n",
    "- a real-valued function $\\varphi$ whose value depends only on the distance from a fixed point\n",
    "    - point is either the origin, so that $\\varphi(\\mathbf{x}) = \\hat{\\varphi}(\\|\\mathbf{x}\\|)$\n",
    "    - a fixed point $\\mathbf{c}$, called a center, so that $\\varphi_c(\\mathbf{x}) = \\hat{\\varphi}(\\|\\mathbf{x} - \\mathbf{c}\\|)$\n",
    "- examples of RBFs:\n",
    "    - Gaussian: $\\varphi(r) = e^{{-(\\epsilon r)}^2}$ where $r = \\|\\mathbf{x} - \\mathbf{c}\\|$ and $\\epsilon$ is a shape parameter\n",
    "    - Multiquadric: $\\varphi(r) = \\sqrt{1 + (\\epsilon r)^2}$\n",
    "    - Inverse quadratic: $\\varphi(r) = \\frac{1}{1 + (\\epsilon r)^2}$\n",
    "    - Inverse multiquadric: $\\varphi(r) = \\frac{1}{\\sqrt{1 + (\\epsilon r)^2}}$\n",
    "    - Thin plate spline: $\\varphi(r) = r^2 \\ln(r)$\n",
    "    - Cubic: $\\varphi(r) = r^3$\n",
    "    - Wendland $\\varphi(r) = (1 - \\epsilon r)^4_+ (4\\epsilon r + 1)$\n",
    "- used to build function approximations of the form $$y(\\mathbf{x}) = \\sum_{i=1}^N w_i \\varphi(\\|\\mathbf{x} - \\mathbf{x}_i\\|)$$\n",
    "    - approximating function is represented as a sum of $N$ radial basis functions, each associated with a different center $\\mathbf{x}_i$, and weighted by an appropriate coefficient $w_i$\n",
    "    - weights $w_i$ can be estimated using the matrix methods of linear least squares, because the approximating function is linear in the weights $w_i$\n",
    "- numerical: finding target value for a new point\n",
    "    - say the data points are [1, 2, 3, 6, 7] and their targets [4, 6, 2, 10, 8]\n",
    "    - new point is $x_{new} = 4$\n",
    "    - choosing Gaussian RBF, $\\varphi(r) = e^{{-(\\epsilon r)}^2}$\n",
    "    - for simplicity, let $\\epsilon = 1$\n",
    "    - choose the data points themselves as the centers, so $\\mathbf{x}_i = [1, 2, 3, 6, 7]$\n",
    "    - RBF for each center using the formula is $\\varphi(x_{new}, c_i) = e^{-1 \\times (x_{new} - c_i)^2}$\n",
    "    - $predicted\\_target = \\frac{\\sum_{i=1}^N target(c_i) \\times \\varphi(x_{new}, c_i)}{\\sum_{i=1}^N \\varphi(x_{new}, c_i)}$\n",
    "- numerical: interpolation function that passes through the data points\n",
    "    - say the data points are (x, y): (1, 2) (2, 3) (3, 4) (4, 5) (5, 6)\n",
    "    - choose 3 centers: $c_1 = 1, c_2 = 3, c_3 = 5$\n",
    "    - choose Gaussian RBF, $\\varphi_i(r) = e^{{-(\\epsilon ||x - c_i||)}^2}$ where $\\epsilon = 1$\n",
    "    - then interpolation function, $F(x) = \\sum_{i=1}^3 w_i \\varphi_i(x, c_i)$\n",
    "    - to find the weights, we need to solve the system of linear equations\n",
    "        1. $2 = w_1 \\varphi_1(1, 1) + w_2 \\varphi_2(1, 3) + w_3 \\varphi_3(1, 5)$\n",
    "        2. $3 = w_1 \\varphi_1(2, 1) + w_2 \\varphi_2(2, 3) + w_3 \\varphi_3(2, 5)$ and so on...\n",
    "\n",
    "\n",
    "### RBF Network\n",
    "- fundamental idea is that an item's predicted target value is likely to be the same as other items with close values of predictor variables\n",
    "- places one or many RBF neurons in the space described by the predictor variables\n",
    "- space has multiple dimensions corresponding to the number of predictor variables present\n",
    "- calculates the Euclidean distance from the evaluated point to the center of each neuron\n",
    "- RBF (kernel function) is applied to the distance to calculate every neuron's weight (influence)\n",
    "- the greater the distance of a neuron from the point being evaluated, the less influence (weight) it has\n",
    "- predict value for new points by adding the output values of RBF functions applied to the distance between the new point and the center of each neuron multiplied by the weight of each neuron\n",
    "- RBF network is a three-layer neural network\n",
    "    - input layer: neurons that receive the input values\n",
    "    - hidden layer: neurons that apply the RBF function to the distance between the input values and the center of each neuron\n",
    "    - output layer: neurons that sum the output values of the hidden layer neurons multiplied by the weight of each neuron $$ y(\\mathbf{x}) = \\sum_{i=1}^N w_i \\varphi(\\|\\mathbf{x} - \\mathbf{x}_i\\|)$$\n",
    "- the approximant $y(\\mathbf{x})$ is differentiable with respect to the weights $w_i$, hence the weights can be estimated using any of the standard iterative methods for neural networks\n",
    "- numerical: RBF network, you have output value for a few 2D points\n",
    "    - method is same as interpolation (pg. 700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines (SVM) [🔗](https://drive.google.com/file/d/12KgpHBHalf4WFJHsVfbim1dQDdVyPk8d/view?usp=drive_link)\n",
    "- maps training examples to points in space so as to maximise the width of the gap between the two categories\n",
    "- new examples are then mapped into that same space and predicted to belong to a category based on which side of the gap they fall\n",
    "- SVMs can efficiently perform a non-linear classification using what is called the kernel trick, implicitly mapping their inputs into high-dimensional feature spaces\n",
    "- [Link](https://shuzhanfan.github.io/2018/05/understanding-mathematics-behind-support-vector-machines/)\n",
    "\n",
    "The functional margin is represented as $\\hat{\\gamma}$ and the geometric margin is represented as $\\gamma$. The geometric margin can be expressed as $\\gamma = \\frac{\\hat{\\gamma}}{||w||}$, where $w$ is the weight vector. So, the geometric margin is a scaled version of the functional margin. Here $\\hat{\\gamma} = y_i(w^Tx_i + b)$. The functional margin represents the correctness and confidence of the prediction if the magnitude of the $w^T$ orthogonal to the hyperplane has a constant value all the time.\n",
    "\n",
    "The functional margin gives the position of a point with respect to the hyperplane, which does not depend on the magnitude. The geometric margin is a scaled version of the functional margin and gives the distance between a given training example and the given hyperplane. It is invariant to the scaling of the vector orthogonal to the hyperplane.\n",
    "\n",
    "The optimization equation for hard margin SVM is to maximize the margin between two classes subject to the constraint that all data points are classified correctly. The margin is defined as the distance between two parallel hyperplanes that separate the two classes. The optimization problem can be expressed as minimizing $\\frac{1}{2}||w||^2$ subject to the constraint $y_i(w^Tx_i + b) \\geq 1$ for all data points $i$. [Video](https://www.youtube.com/watch?v=vNt_WCM1M3M&list=PLAoF4o7zqskR7U98D799FKHkZ4YrHKPqs&index=82)\n",
    "\n",
    "The primal optimization problem for SVM is $$ L(w, b, \\alpha) = \\frac{1}{2}||w||^2 - \\sum_{i=1}^n \\alpha_i[y_i(w^Tx_i + b) - 1] $$\n",
    "\n",
    "The dual optimization problem for SVM is \n",
    "$$ \\Theta_D(\\alpha) = \\min_{w, b} L(w, b, \\alpha) $$\n",
    "\n",
    "Solving for $w$ and $b$ in the dual optimization problem gives $$ \\Theta_D(\\alpha) = \\sum_{i=1}^n \\alpha_i - \\frac{1}{2}\\sum_{i=1}^n \\sum_{j=1}^n \\alpha_i \\alpha_j y_i y_j <x_i^T x_j> $$\n",
    "\n",
    "This gives us the dual problem, which is a quadratic optimization problem. The dual problem is easier to solve than the primal problem because it is a convex optimization problem. It is given by $$ \\max_{\\alpha} \\Theta_D(\\alpha) $$ subject to $ \\sum_{i=1}^n \\alpha_i y_i = 0 $ and $ \\alpha_i \\geq 0 $ for all $i$.\n",
    "\n",
    "So we can first solve for $\\alpha$ using the dual optimization problem, and then solve for $w$ and $b$ using the values of $\\alpha$.\n",
    "\n",
    "#### Kernel Trick\n",
    "\n",
    "Kernel functions are functions that map data points from a low-dimensional space to a higher-dimensional space. The kernel function is used to transform the data into a higher-dimensional space so that the data becomes linearly separable. The kernel function is defined as $$ K(x_i, x_j) = \\phi(x_i)^T \\phi(x_j) $$ where $\\phi(x_i)$ is the transformed data point. The kernel function is a dot product between the transformed data points.\n",
    "\n",
    "Equation of linear kernel function is $$ K(x_i, x_j) = x_i^T x_j $$\n",
    "Equation of polynomial kernel function is $$ K(x_i, x_j) = (x_i^T x_j + c)^d $$\n",
    "Equation of radial basis function kernel function is $$ K(x_i, x_j) = \\exp(\\gamma ||x_i - x_j||^2) $$\n",
    "    - small value of $\\gamma$ will make the model behave like a linear SVM\n",
    "    - large value of $\\gamma$ will make the model heavily impacted by the support vectors examples\n",
    "Equation of sigmoid kernel function is $$ K(x_i, x_j) = \\tanh(\\beta x_i^T x_j + \\theta) $$\n",
    "\n",
    "#### Soft margin SVM\n",
    "\n",
    "The optimization problem is given by $$ \\min_{w, b} \\frac{1}{2}||w||^2 + C \\sum_{i=1}^n \\xi_i $$ subject to $ y_i(w^Tx_i + b) \\geq 1 - \\xi_i $ and $ \\xi_i \\geq 0 $ for all $i$.\n",
    "\n",
    "In soft margin SVM, a slack variable $\\xi_i$ is introduced for every data point $x_i$. The value of $\\xi_i$ is the distance of $x_i$ from the corresponding class’s margin if $x_i$ is on the wrong side of the margin, otherwise zero¹. This allows some misclassifications to happen while keeping the margin as wide as possible so that other points can still be classified correctly.\n",
    "\n",
    "#### Regularization parameter C\n",
    "- determines how important $xi$ should be\n",
    "    - smaller $C$ emphasizes the importance of $xi$\n",
    "    - larger $C$ diminishes the importance of $xi$\n",
    "- controls how the SVM will handle errors\n",
    "    - if $C$ is positive infinite, then we will get the same result as the hard margin SVM\n",
    "    - if $C$ is 0, then there will be no constraint anymore, and we will end up with a hyperplane not classifying anything\n",
    "- small values of $C$ will result in a wider margin, at the cost of some misclassifications\n",
    "- large values of $C$ will give you the hard margin classifier and tolerates zero constraint violation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes classifier\n",
    "\n",
    "- Naive Bayes classifier is a simple probabilistic classifier based on applying Bayes' theorem with strong independence assumptions between the features.\n",
    "- We have a set of features $X = {X_1, X_2, ..., X_n}$ and a class variable $Y$.\n",
    "- We want to find the class $Y$ that maximizes the posterior probability $P(Y|X)$.\n",
    "- Then $$ P(Y = y_k|X_1, X_2, ..., X_n) = \\frac{P(Y = y_k)P(X_1, X_2, ..., X_n|Y = y_k)}{\\sum\\limits_{j} P(Y = y_j)P(X_1, X_2, ..., X_n|Y = y_j)} $$\n",
    "- Assuming conditional independence, we have $P(X_1, X_2, ..., X_n|Y = y_k) = \\prod\\limits_{i=1}^n P(X_i|Y = y_k)$. Therefore, $$P(Y = y_k|X_1, X_2, ..., X_n) = \\frac{P(Y = y_k)\\prod\\limits_{i=1}^n P(X_i|Y = y_k)}{\\sum\\limits_{j} P(Y = y_j)\\prod\\limits_{i=1}^n P(X_i|Y = y_j)}$$\n",
    "- Pick the most probable class: $$\\hat{y} = \\arg\\max\\limits_{y_k} P(Y = y_k)\\prod\\limits_{i} P(X_i|Y = y_k)$$\n",
    "\n",
    "Steps to apply Naive Bayes classifier, given a table like this:\n",
    "\n",
    "|Weather|Play|\n",
    "|---|---|\n",
    "|Sunny|No|\n",
    "|...|...|\n",
    "|Rainy|Yes|\n",
    "\n",
    "We convert it into a frequency table like this:\n",
    "\n",
    "|Weather|No|Yes|Total|Prob|\n",
    "|---|---|---|---|---|\n",
    "|Sunny|2|3|5| P(Sunny) = $\\frac{5}{14}$|\n",
    "|Overcast|0|4|4| P(Overcast) = $\\frac{4}{14}$|\n",
    "|Rainy|3|2|5| P(Rainy) = $\\frac{5}{14}$|\n",
    "|Total|5|9|14|1|\n",
    "|Prob|P(No) = $\\frac{5}{14}$|P(Yes) = $\\frac{9}{14}$|1|\n",
    "\n",
    "Then we can calculate the posterior probability of each class, given the evidence (weather), for example, $P(Yes|Sunny)$:\n",
    "$$ P(Yes|Sunny) = \\frac{P(Sunny|Yes)P(Yes)}{P(Sunny)} = \\frac{\\frac{3}{9}\\frac{9}{14}}{\\frac{5}{14}} = \\frac{3}{5}$$\n",
    "\n",
    "If there are multiple features, we can calculate the posterior probability of each class, given the evidence (weather and temperature), for example, $P(Yes|Sunny, Cool)$:\n",
    "$$ P(Yes|Sunny, Cool) = \\frac{P(Sunny, Cool|Yes)P(Yes)}{P(Sunny, Cool)} = \\frac{P(Sunny|Yes)P(Cool|Yes)P(Yes)}{P(Sunny)P(Cool)} $$\n",
    "\n",
    "## Naive Bayes for text classification\n",
    "You need a document $d$, a set of classes $C = {c_1, c_2, ..., c_n}$, and a set of $m$ hand-labelled documents $(d_1, c_1), (d_2, c_2), ..., (d_m, c_m)$. The for a document $d$, we want to find the class $c$ that maximizes the posterior probability $P(c|d)$.\n",
    "$$ P(c|d) = \\frac{P(c)P(d|c)}{P(d)} = \\frac{P(c)\\prod\\limits_{i=1}^n P(w_i|c)}{P(d)}$$\n",
    "Here, there are two assumptions : bag of words (position doesn't matter) and conditional independence.\n",
    "Then, we pick the most probable class: $$c_{MAP} = \\arg\\max\\limits_{c} P(c)\\prod\\limits_{i=1}^n P(w_i|c)$$\n",
    "Here, $$ P(c_j) = \\frac{docCount(C = c_j)}{N_{doc}} $$ and $$ P(w_i|c_j) = \\frac{wordCount(w_i, C = c_j)}{\\sum\\limits_{w \\in V} wordCount(w, C = c_j)} $$, where $V$ is the vocabulary.\n",
    "This has a problem of zero probability, so we use Laplace smoothing: $$ P(w_i|c_j) = \\frac{wordCount(w_i, C = c_j) + 1}{\\sum\\limits_{w \\in V} wordCount(w, C = c_j) + |V|} $$\n",
    "\n",
    "[Example](https://www.fi.muni.cz/~sojka/PV211/p13bayes.pdf):\n",
    "<img src=\"https://i.imgur.com/p3nZUNM.png\" width=\"500\" style=\"display: block; margin-left: auto; margin-right: auto; padding-top: 10px; padding-bottom: 10px;\">\n",
    "<img src=\"https://i.imgur.com/kcNsCro.png\" width=\"500\" style=\"display: block; margin-left: auto; margin-right: auto; padding-top: 10px; padding-bottom: 10px;\">\n",
    "\n",
    "Therefore, $$P(C|d_5) = \\frac{3}{4} {(\\frac{3}{7})}^3 \\frac{1}{14} \\frac{1}{14} \\frac{1}{P(d_5)}$$\n",
    "and $$P(\\bar{C} | d_5) = \\frac{1}{4} {(\\frac{2}{9})}^3 \\frac{2}{9} \\frac{2}{9} \\frac{1}{P(d_5)}$$\n",
    "\n",
    "$P(d_5)$ is the same for both classes, so we can ignore it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble learning\n",
    "\n",
    "- Ensemble learning is a machine learning paradigm where multiple learners are trained to solve the same problem, and then combined to get better results.\n",
    "- types of ensemble methods:\n",
    "1. bagging - decrease variance\n",
    "    - building multiple models (typically of the same type) from different subsamples of the training dataset (with replacement) \n",
    "    - considers homogeneous weak learners, learns them independently from each other in parallel and combines them following some kind of deterministic averaging process\n",
    "    - eg. random forest, extra trees\n",
    "2. boosting - decrease bias\n",
    "    - building multiple models (typically of the same type) each of which learns to fix the prediction errors of a prior model in the chain\n",
    "    - considers homogeneous weak learners, learns them sequentially in a very adaptative way (a base model depends on the previous ones) and combines them following a deterministic strategy\n",
    "3. stacking  - increase predictive power\n",
    "    - building multiple models (typically of differing types) and supervisor model that learns how to best combine the predictions of the base models\n",
    "    - considers heterogeneous weak learners, learns them in parallel and combines them by training a meta-model to output a prediction based on the different weak models predictions\n",
    "\n",
    "### Random forest vs Extra trees\n",
    "- Random forest is an ensemble learning method for classification, regression and other tasks that operates by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees. Random decision forests correct for decision trees' habit of overfitting to their training set. The steps for random forest are:\n",
    "    1. Sample $n$ cases at random with replacement to create a subset of the data, called the bag used to build a tree\n",
    "    2. At each node, randomly select $d$ features without replacement\n",
    "    3. Calculate the best split point for the selected features\n",
    "    4. Split the node into two daughter nodes\n",
    "    5. Repeat steps 1 to 4 $k$ times\n",
    "    6. Aggregate the prediction by each tree to assign the class label by majority vote (classification) or average (regression)\n",
    "- Extra trees is an ensemble learning method for classification, regression and other tasks that constructs a multitude of decision trees at training time and outputs the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees. Extra-trees differ from classic decision trees in the way they are built. When looking for the best split to separate the samples of a node into two groups, random splits are drawn for each of the max_features randomly selected features and the best split among those is chosen. When max_features is set 1, this amounts to building a totally random decision tree.\n",
    "\n",
    "### AdaBoost vs Gradient Boosting vs XGBoost\n",
    "- AdaBoost is an ensemble learning method for classification and regression. It is a meta-algorithm, and can be used in conjunction with many other learning algorithms to improve their performance. The output of the other learning algorithms ('weak learners') is combined into a weighted sum that represents the final output of the boosted classifier. AdaBoost is adaptive in the sense that subsequent weak learners are tweaked in favor of those instances misclassified by previous classifiers. AdaBoost is sensitive to noisy data and outliers.\n",
    "\n",
    "<img src=\"https://i.imgur.com/uYsoCL2.png\" width=\"400\" style=\"display: block; margin-left: auto; margin-right: auto; padding-top: 10px; padding-bottom: 10px;\">\n",
    "\n",
    "- Gradient boosting is a machine learning technique for regression and classification problems, which produces a prediction model in the form of an ensemble of weak prediction models, typically decision trees. It builds the model in a stage-wise fashion like other boosting methods do, and it generalizes them by allowing optimization of an arbitrary differentiable loss function. Gradient boosting is a greedy algorithm and can overfit if run for too many iterations.\n",
    "\n",
    "<img src=\"https://i.imgur.com/Fz2HzoG.png\" width=\"400\" style=\"display: block; margin-left: auto; margin-right: auto; padding-top: 10px; padding-bottom: 10px;\">\n",
    "\n",
    "- XGBoost is short for eXtreme Gradient Boosting. It is an optimized distributed gradient boosting library. It provides a parallel tree boosting (also known as GBDT, GBM) that solves many ML problems quickly and accurately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering\n",
    "\n",
    "- Clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense) to each other than to those in other groups (clusters).\n",
    "\n",
    "### K-means clustering\n",
    "- K-means clustering aims to partition $n$ observations into $k$ clusters in which each observation belongs to the cluster with the nearest mean, serving as a prototype of the cluster. This results in a partitioning of the data space into Voronoi cells.\n",
    "    - K-means clustering minimizes within-cluster variances (squared Euclidean distances)\n",
    "    - Given a set of observations $(x_1, x_2, ..., x_n)$, where each observation is a $d$-dimensional real vector, k-means clustering aims to partition the $n$ observations into $k$ sets $S = {S_1, S_2, ..., S_k}$ so as to minimize the within-cluster sum of squares (WCSS) $$ \\sum_{i=1}^k \\sum_{x \\in S_i} ||x - \\mu_i||^2 $$ where $\\mu_i$ is the mean of points in $S_i$.\n",
    "\n",
    "#### Evaluation metrics\n",
    "- Distortion\n",
    "    - the average of the squared distances from the cluster centers of the respective clusters. Typically, the Euclidean distance metric is used.\n",
    "    - The distortion is given by $$ J = \\sum_{i=1}^k \\frac{1}{|S_i|} \\sum_{x \\in S_i} ||x - \\mu_i||^2 $$\n",
    "- Inertia\n",
    "    - the sum of squared distances of samples to their closest cluster center.\n",
    "    - The inertia is given by $$ I = \\sum_{i=1}^k \\sum_{x \\in S_i} ||x - \\mu_i||^2 $$\n",
    "\n",
    "- Dunn index\n",
    "    - the ratio between the minimum inter-cluster distance to maximum intra-cluster distance. The higher the value of Dunn index, the better the clustering.\n",
    "    - The Dunn index is defined as $$ D = \\frac{\\min\\limits_{1 \\leq i < j \\leq n} d(i, j)}{\\max\\limits_{1 \\leq k \\leq n} \\Delta(k)} = \\frac{\\min(\\text{inter-cluster distance})}{\\max(\\text{intra-cluster distance})}$$ where $d(i, j)$ is the distance between clusters $i$ and $j$, and $\\Delta(k)$ is the diameter of cluster $k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Points: [[1 1]\n",
      " [2 2]\n",
      " [2 3]\n",
      " [1 2]\n",
      " [5 6]\n",
      " [5 7]\n",
      " [6 7]\n",
      " [6 6]]\n",
      "Iteration 1:\n",
      "Centroids: [[1. 1.]\n",
      " [5. 6.]]\n",
      "Distances: [[0.         6.40312424]\n",
      " [1.41421356 5.        ]\n",
      " [2.23606798 4.24264069]\n",
      " [1.         5.65685425]\n",
      " [6.40312424 0.        ]\n",
      " [7.21110255 1.        ]\n",
      " [7.81024968 1.41421356]\n",
      " [7.07106781 1.        ]]\n",
      "Iteration 2:\n",
      "Centroids: [[1.5 2. ]\n",
      " [5.5 6.5]]\n",
      "Distances: [[1.11803399 7.1063352 ]\n",
      " [0.5        5.70087713]\n",
      " [1.11803399 4.94974747]\n",
      " [0.5        6.36396103]\n",
      " [5.31507291 0.70710678]\n",
      " [6.10327781 0.70710678]\n",
      " [6.72681202 0.70710678]\n",
      " [6.02079729 0.70710678]]\n",
      "Iteration 3:\n",
      "Centroids: [[1.5 2. ]\n",
      " [5.5 6.5]]\n",
      "Distances: [[1.11803399 7.1063352 ]\n",
      " [0.5        5.70087713]\n",
      " [1.11803399 4.94974747]\n",
      " [0.5        6.36396103]\n",
      " [5.31507291 0.70710678]\n",
      " [6.10327781 0.70710678]\n",
      " [6.72681202 0.70710678]\n",
      " [6.02079729 0.70710678]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the number of clusters and the number of iterations\n",
    "K = 2\n",
    "max_iterations = 3\n",
    "\n",
    "# Generate some sample data\n",
    "# data = np.random.randint(0, 10, size=(5, 2))\n",
    "data = np.array([[1, 1], [2, 2], [2, 3], [1, 2], [5,6], [5, 7], [6, 7], [6, 6]])\n",
    "print(f\"Points: {data}\")\n",
    "\n",
    "# Initialize the centroids by randomly selecting K data points\n",
    "# centroids = data[np.random.choice(data.shape[0], K, replace=False)]\n",
    "centroids = np.array([[1, 1], [5, 6]])\n",
    "centroids = centroids.astype(float)\n",
    "\n",
    "# Iterate the k-means algorithm\n",
    "for i in range(max_iterations):\n",
    "    # Assign each point to the nearest centroid\n",
    "    distances = np.sqrt(np.sum((data[:, np.newaxis, :] - centroids) ** 2, axis=2))\n",
    "    labels = np.argmin(distances, axis=1)\n",
    "    \n",
    "    # Print the centroids and the distances at each iteration\n",
    "    print(f\"Iteration {i+1}:\")\n",
    "    print(f\"Centroids: {centroids}\")\n",
    "    print(f\"Distances: {distances}\")\n",
    "    \n",
    "    # Update the centroids to the mean of the assigned points  \n",
    "    for k in range(K):\n",
    "        centroids[k] = np.mean(data[labels == k], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means++ algorithm\n",
    "\n",
    "- K-means++ algorithm is an algorithm for choosing the initial values (or \"seeds\") for the k-means clustering algorithm\n",
    "- The algorithm is as follows:\n",
    "    1. Choose one center uniformly at random from among the data points.\n",
    "    2. For each data point $x$, compute $D(x)$, the distance between $x$ and the nearest center that has already been chosen.\n",
    "    3. Choose one new data point at random as a new center, using a weighted probability distribution where a point $x$ is chosen with probability proportional to $D(x)^2$.\n",
    "    4. Repeat Steps 2 and 3 until $k$ centers have been chosen.\n",
    "    5. Now that the initial centers have been chosen, proceed using standard k-means clustering.\n",
    "- The k-means++ seeding method gives a provable upper bound on the expected running time of the resulting k-means algorithm, which is nearly-optimal up to constant factors.\n",
    "- main advantage is that it helps avoid poor local minima, by ensuring a more spread out initial set of centers, leading to faster convergence and better final solution\n",
    "\n",
    "### K Medoids clustering\n",
    "- k-medoids chooses datapoints as centers (medoids or exemplars) and forms clusters around them. It is similar to k-means clustering, but the difference is that the center of the cluster is always a data point. In k-means, the center of the cluster is the mean of the data points in the cluster.\n",
    "- The algorithm is as follows:\n",
    "    1. Initialize: randomly select $k$ of the $n$ data points as the medoids\n",
    "    2. Associate each data point to the closest medoid. (Thus forming $k$ clusters of data points.)\n",
    "    3. For each cluster $k$ and its medoid $m$:\n",
    "        - For each non-medoid data point $o$ in the cluster:\n",
    "            - Swap $o$ and $m$ and compute the total cost of the configuration\n",
    "        - Select the configuration with the lowest cost.\n",
    "    4. Repeat Steps 2 and 3 until there is no change in the medoid.\n",
    "\n",
    "### Fuzzy C-means clustering\n",
    "- Fuzzy C-means clustering is a method of clustering which allows one piece of data to belong to two or more clusters\n",
    "- The algorithm is as follows:\n",
    "    1. Specify the number of clusters $c$ and the fuzzy parameter $m$.\n",
    "    2. Initialize the cluster centers randomly, $v_j \\in \\mathbb{R}^d$ for $j = 1, 2, ..., c$.\n",
    "    3. For each data point, compute the degree of membership of that point to each cluster center: $$\\mu_{ij} = \\frac{1}{\\sum\\limits_{k=1}^c \\left( \\frac{d_{ij}}{d_{kj}} \\right) ^ \\frac{2}{m-1}}$$ where $d_{ij}$ is the distance between the $i^{th}$ data point and the $j^{th}$ cluster center.\n",
    "    4. Recompute the cluster centers: $$v_j = \\frac{\\sum\\limits_{i=1}^n \\mu_{ij}^m x_i}{\\sum\\limits_{i=1}^n \\mu_{ij}^m}$$\n",
    "    5. Repeat Steps 3 and 4 until the membership coefficients $\\mu_{ij}$ do not change.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expectation Maximization (EM) algorithm\n",
    "- Expectation Maximization (EM) algorithm is an iterative method for finding maximum likelihood or maximum a posteriori (MAP) estimates of parameters in statistical models, where the model depends on unobserved latent variables. The EM iteration alternates between:\n",
    "    - Expectation step (E-step): create a function for the expectation of the log-likelihood evaluated using the current estimate for the parameters\n",
    "        $$ Q(\\theta | \\theta^{(t)}) = E_{Z|X, \\theta^{(t)}} [\\log L(\\theta; X, Z)] $$\n",
    "    - Maximization step (M-step): compute parameters maximizing the expected log-likelihood found on the E-step\n",
    "        $$ \\theta^{(t+1)} = \\arg\\max\\limits_{\\theta} Q(\\theta | \\theta^{(t)}) $$\n",
    "- The EM algorithm is guaranteed to converge to a local maximum, but not necessarily to the global maximum of the likelihood. In practice, EM can be susceptible to getting stuck in local maxima, so multiple restarts are used. The EM algorithm can also be generalized to maximize incomplete-data likelihood functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation / Comparison\n",
    "\n",
    "### Confidence Interval for Accuracy\n",
    "$$ CI = \\hat{p} \\pm z_{\\alpha/2} \\sqrt{\\frac{\\hat{p}(1 - \\hat{p})}{n}} $$\n",
    "where $\\hat{p}$ is the observed accuracy, $z_{\\alpha/2}$ is the critical value of the normal distribution at $\\alpha/2$ (e.g. for 95% confidence interval, $\\alpha = 0.05$ and $z_{\\alpha/2} = 1.96$), and $n$ is the number of test instances."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
