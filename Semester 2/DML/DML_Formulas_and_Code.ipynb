{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Management for Machine Learning Concepts and Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Models \n",
    "\n",
    "- describes how data is represented in terms of attributes and relationships\n",
    "    - car can be represented by attributes such as make, model, year, color, etc, as well as owner, license plate, etc\n",
    "- applications built by layering one data model on top of another\n",
    "- many different data models exist, which\n",
    "    - embody different assumptions about the data\n",
    "    - are suited to different types of applications\n",
    "- selecting data model affects how data is stored, queried, and updated\n",
    "    - ways systems are built, problems that can be solved, and performance characteristics\n",
    "\n",
    "### Relational Data Model\n",
    "- Edgar Codd, 1970\n",
    "- data is represented as a collection of relations (tables)\n",
    "    - each relation has a set of named attributes (columns)\n",
    "    - each tuple (row) has a value for each attribute\n",
    "    - unordered, can shuffle rows and columns\n",
    "    - usually stored in csv or parquet format\n",
    "- normalization\n",
    "    - process of decomposing relations with anomalies into smaller, well-structured relations (1ND, 2NF, 3NF, BCNF etc)\n",
    "    - reduces redundancy and improves data integrity\n",
    "    - can be expensive to compute\n",
    "- databases built around relational model are called relational databases\n",
    "    - most common type of database\n",
    "    - SQL is the most common language for querying and manipulating data in relational databases\n",
    "    - examples: MySQL, PostgreSQL, SQLite, Oracle, Microsoft SQL Server, IBM DB2\n",
    "\n",
    "#### SQL \n",
    "- is a declarative language\n",
    "- user specifies what data they want, not how to get it\n",
    "    - tables, conditions, transformations such as joins and aggregations\n",
    "- query optimizer determines how to execute query\n",
    "    - which tables to read, which indexes to use, etc\n",
    "    - how to break query into smaller subqueries, order of operations, etc\n",
    "- generalized a lot but is still restrictive, needs a strict schema, schema changes are expensive\n",
    "\n",
    "### NoSQL\n",
    "- non-relational databases\n",
    "- retroactively reinforced as \"not only SQL\"\n",
    "- data is stored in a variety of ways\n",
    "    - key-value / document stores\n",
    "        - targets use cases where data comes in self-contained documents\n",
    "        - single continuous string of data, encoded as JSON, XML, or similar format\n",
    "        - each document has a unique key that is used to retrieve it\n",
    "    - wide-column stores\n",
    "        - targets use cases where data is stored in sparse tables, with many columns\n",
    "        - each row has a unique key, but unlike key-value stores, each row can have different columns\n",
    "        - each column has a name and a value\n",
    "        - examples: Cassandra, HBase, BigTable\n",
    "    - graph databases\n",
    "        - targets use cases where data has complex relationships between data entities exist and are important\n",
    "- does not enforce a schema\n",
    "    - misleading, as schema is still assumed by the reader of the data\n",
    "    - shifts the burden of ensuring data integrity from the database to the application\n",
    "- has better locality than relational databases\n",
    "    - data with complex relationships can be stored together and retrieved in one operation\n",
    "    - can be faster than relational databases for some use cases\n",
    "    - but difficult to execute joins over data from different entities\n",
    "- examples: MongoDB, Cassandra, HBase, Neo4j, Redis, CouchDB\n",
    "\n",
    "| Data Type | Definition | Examples | Advantages | Disadvantages |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| Structured Data | This type of data is organized in a highly systematic and predictable manner. It is usually stored in relational databases and can be efficiently queried using a language like SQL. | Databases, CSV files, Excel spreadsheets. | Easy to store, search, and analyze. High accuracy and reliability. | Lack of flexibility. Not suitable for complex, hierarchical, or multi-dimensional data. |\n",
    "| Semi-Structured Data | This type of data does not conform to the formal structure of data models, but contains tags and other markers to separate semantic elements. It is more flexible than structured data, but less organized than unstructured data. | XML, JSON, NoSQL databases. | More flexible than structured data. Can represent more complex and hierarchical relationships. | Less efficient to query and process than structured data. Requires more storage. |\n",
    "| Unstructured Data | This type of data doesn't have a predefined model or is not organized in a predefined manner. It is typically text-heavy, but can also be in the form of images, videos, etc. | Emails, Word documents, PDFs, images, videos, web pages. | Highly flexible. Can represent any type of information. | Difficult to analyze and process. Requires advanced tools and algorithms, such as Natural Language Processing (NLP) for text, or Computer Vision for images and videos. |\n",
    "\n",
    "### Data Warehouses and Data Lakes\n",
    "- data warehouse\n",
    "    - database that is optimized for analytics\n",
    "    - typically used to store structured data\n",
    "    - often used for reporting and dashboarding\n",
    "    - examples: Amazon Redshift, Google BigQuery, Snowflake\n",
    "- data lake\n",
    "    - repository for structured and unstructured data\n",
    "    - typically used for storing large amounts of raw data before processing\n",
    "    - examples: Amazon S3, Google Cloud Storage, Hadoop File System (HDFS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Management\n",
    "- about transforming data into a format that is more convenient to work with for later stages of the pipeline\n",
    "- apply data transformations to make data easier to work with\n",
    "    - filtering, aggregating, joining, sorting, etc\n",
    "- train models, anonymize data, etc\n",
    "- delete data that is no longer needed\n",
    "\n",
    "### Multi-phases\n",
    "1. creation\n",
    "    - data created in process, outside of our control, captured in some storage system\n",
    "    - some are:\n",
    "        - static (infrequently updated) eg. photo recognition dataset\n",
    "        - dynamic (frequently updated / real-time) eg. stock market data\n",
    "    - may be structured, semi-structured, or unstructured\n",
    "        - requires different tools and techniques in each case\n",
    "    - may require augmentation, to make it more useful\n",
    "        - eg. adding labels to images, adding timestamps to stock market data    \n",
    "2. ingestion\n",
    "    - filtering / selection / sampling may be done\n",
    "        - we may not necessarily want to keep all the data\n",
    "        - sampling may lose some details, but may be necessary for performance reasons, trade-off between quality cost of model and savings in time and money\n",
    "    - may be simple or complex\n",
    "        - dumping data into a database, or running a complex ETL pipeline\n",
    "    - may be done in real-time or in batches\n",
    "    - reliability concerns focus on correctness and throughput\n",
    "        - correctness: is the data being ingested correctly?\n",
    "        - throughput: how fast can we ingest data?\n",
    "    - monitoring existence and condition of data before and during ingestion is the most difficult part of the process\n",
    "- processing (validation, cleaning, enrichment)\n",
    "- post-processing (data management, storage, analysis, visualization)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
