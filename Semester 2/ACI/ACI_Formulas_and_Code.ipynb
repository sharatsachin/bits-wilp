{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artificial and Computational Intelligence Formulas and Code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artificial Intelligence\n",
    "\n",
    "Artificial Intelligence (AI) is the simulation of human intelligence in machines that are programmed to think and act like humans. AI can be classified into two categories:\n",
    "- **Narrow or Weak AI**: AI that is designed to perform a specific task, such as playing chess or recognizing speech.\n",
    "- **General or Strong AI**: AI that has the ability to perform any intellectual task that a human can.\n",
    "\n",
    "#### Definition\n",
    "- the simulation of human intelligence processes by machines, especially computer systems\n",
    "- processes include learning, reasoning, problem-solving, perception, and language understanding\n",
    "- aspects :\n",
    "1. Acting Humanly: The Turing Test Approach\n",
    "    - proposed by Alan Turing (1950), is designed to provide a satisfactory operational definition of intelligence\n",
    "    - computer passes the test if a human interrogator, after posing some written questions, cannot tell whether the written responses come from a person or from a computer\n",
    "    - skills required : NLP, knowledge representation, automated reasoning, machine learning, computer vision, robotics\n",
    "2. Thinking Humanly: The Cognitive Modeling Approach\n",
    "    - involves having machines understand, mimic, and replicate human thought processes\n",
    "    - cognitive science brings together computer models from AI and experimental techniques from psychology to construct precise and testable theories of the human mind\n",
    "    - skills required : cognitive science, neuroscience, philosophy\n",
    "3. Thinking Rationally: The \"Laws of Thought\" Approach\n",
    "    - programming computers to mimic the cognitive processes humans go through when they're thinking rationally\n",
    "    - could involve logical reasoning or decision-making processes\n",
    "    - skills required : logic, algorithms, probability\n",
    "4. Acting Rationally: The Rational Agent Approach\n",
    "    - rational agent is one that acts so as to achieve the best outcome or, when there is uncertainty, the best expected outcome\n",
    "    - skills required : game theory, economics, decision theory\n",
    "    - `(percept sequence) -> (agent function) -> (action sequence)`\n",
    "\n",
    "#### Applications of AI\n",
    "\n",
    "AI has a wide range of applications in various fields, including:\n",
    "\n",
    "- **Healthcare**: AI can be used to diagnose diseases, develop personalized treatment plans, and monitor patient health.\n",
    "- **Finance**: AI can be used for fraud detection, risk assessment, and investment analysis.\n",
    "- **Transportation**: AI can be used for autonomous vehicles, traffic management, and logistics optimization.\n",
    "- **Education**: AI can be used for personalized learning, student assessment, and educational research.\n",
    "\n",
    "### Computational Intelligence\n",
    "\n",
    "Computational Intelligence (CI) is a subfield of AI that focuses on the development of intelligent algorithms that can learn from data and adapt to new situations. CI can be classified into three categories:\n",
    "\n",
    "- **Neural Networks**: CI that is inspired by the structure and function of the human brain.\n",
    "- **Fuzzy Systems**: CI that is based on the theory of fuzzy sets, which allows for reasoning with uncertain or imprecise information.\n",
    "- **Evolutionary Computation**: CI that is based on the principles of natural selection and genetic algorithms.\n",
    "\n",
    "#### Applications of CI\n",
    "\n",
    "CI has a wide range of applications in various fields, including:\n",
    "\n",
    "- **Data Mining**: CI can be used to extract useful information from large datasets.\n",
    "- **Robotics**: CI can be used to develop intelligent robots that can perform complex tasks.\n",
    "- **Image Processing**: CI can be used to enhance and analyze digital images and videos.\n",
    "- **Natural Language Processing**: CI can be used to understand and generate human language."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intelligent Agents\n",
    "\n",
    "- program that perceives its environment through sensors and acts upon that environment through actuators\n",
    "- PEAS description of task environment\n",
    "    - Performance measure\n",
    "    - Environment\n",
    "    - Actuators\n",
    "    - Sensors\n",
    "- table with PEAS environment for Medical diagnosis system, satellite image analysis system, interactive English tutor\n",
    "\n",
    "| Agent Type              | Performance Measure     | Environment               | Actuators                          | Sensors                      |\n",
    "|-------------------------|-------------------------|---------------------------|------------------------------------|------------------------------|\n",
    "| Medical diagnosis system| Healthy patient, reduced costs | Patient, hospital, staff | Display of questions, tests, diagnoses, treatments, referrals | Keyboard entry of symptoms, findings, patient’s answers |\n",
    "| Satellite image analysis system | Correct image categorization | Downlink from orbiting satellite | Display of scene categorization | Color pixel arrays |\n",
    "| Part-picking robot      | Percentage of parts in correct bins | Conveyor belt with parts; bins | Jointed arm and hand | Camera, joint angle sensors |\n",
    "| Refinery controller     | Purity, yield, safety | Refinery, operators | Valves, pumps, heaters, displays | Temperature, pressure, chemical sensors |\n",
    "| Interactive English tutor | Student’s score on test | Set of students, testing agency | Display of exercises, suggestions, corrections | Keyboard entry |\n",
    "\n",
    "#### Task Environment Dimensions\n",
    "1. sensing\n",
    "    - fully observable : sensors give access to the complete state of the environment at each point in time\n",
    "    - partially observable : sensors give access to only partial state of the environment at each point in time\n",
    "2. state determinism\n",
    "    - deterministic : next state of environment is completely determined by current state and action executed by agent\n",
    "    - stochastic : next state of environment is not completely determined by current state and action executed by agent\n",
    "3. action dependance\n",
    "    - episodic : agent's experience is divided into atomic episodes, agent's next action does not depend on actions taken earlier\n",
    "    - sequential : agent's next action depends on actions taken earlier\n",
    "4. state continuity\n",
    "    - static : environment is unchanged while agent is deliberating\n",
    "    - dynamic : environment can change while agent is deliberating\n",
    "    - semi-dynamic : environment does not change with passage of time, but the agent's performance score does\n",
    "5. number of agents\n",
    "    - single agent : agent is operating by itself\n",
    "    - multiagent : agent is operating with other agents\n",
    "6. number of states / actions\n",
    "    - discrete : finite number of states / actions, represented by integers\n",
    "    - continuous : infinite number of states / actions, represented by real numbers\n",
    "\n",
    "- table with task environment dimensions for medical diagnosis system, satellite image analysis system, interactive English tutor\n",
    "\n",
    "| Task Environment | Fully / Partially Observable | Single / Multi Agent | Deterministic / Stochastic | Episodic / Sequential | Static / Dynamic / Semi-Dynamic | Discrete / Continuous |\n",
    "| --- | --- | --- | --- | --- | --- | --- |\n",
    "| Medical diagnosis system | partially | single | stochastic | sequential | dynamic | continuous |\n",
    "| Satellite image analysis system | fully | single | deterministic | episodic | static | continuous |\n",
    "| Interactive English tutor | partially | multiagent | stochastic | sequential | dynamic | discrete |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent Architectures\n",
    "\n",
    "| Agent Type | Description | Example |\n",
    "| -- | -- | -- |\n",
    "| Reflex Agents    | - Makes decision based on current percept only, without considering history of previous percepts or actions<br>- Uses set of predefined rules or condition-action pairs to determine its actions<br>- Selects action based on current state of environment and corresponding rule that matches percept<br>- Does not have internal representation or model of world<br>- Typically simple and efficient but lack ability to plan or reason about future states                                  | A simple reflex agent for vacuum cleaning robot may have rule that says \"if current location is dirty, then vacuum the location; otherwise, move to next location\" |\n",
    "| Model-Based Agents| - Maintains internal model or representation of world<br>- Uses this model to keep track of state of environment, as well as possible actions and their outcomes<br>- Uses model to infer how environment will evolve in response to its actions                                                                                    | A chess-playing agent may have model that represents current state of board and possible moves that can be made by each player, can use this model to predict how board will look after each possible move and select move that leads to best outcome |\n",
    "| Goal-Based Agents | - Operates based on set of predefined goals or objectives<br>- Has knowledge about current state of environment and uses this information to determine actions required to achieve goals<br>- Continually assesses current state, compares it to desired goal state, and selects actions that bring it closer to achieving objectives<br>- Often employs search algorithms or planning techniques to find sequence of actions that will lead to goals<br>- Considers current state, available actions, and transition model of environment to make decisions  | A delivery robot that aims to deliver packages to specific locations would have goal-based agent, evaluates current state such as location of packages and obstacles, and plans actions to navigate environment efficiently and complete deliveries |\n",
    "| Utility-Based Agents | - Operates based on utility function that maps state of environment to real number representing degree of satisfaction or desirability of that state<br>- Selects actions that maximize expected utility<br>- Considers current state, available actions, and transition model of environment to make decisions<br>- Typically used in domains where goals are not well-defined or known                                                     | An autonomous car navigating in traffic could be considered utility-based agent, evaluates factors such as safety, efficiency, and passenger comfort when selecting actions, aiming to maximize overall utility of journey |\n",
    "| Learning Agents  | - Intelligent agents that can acquire knowledge and improve their performance through experience<br>- Learn from interactions with environment, including feedback and rewards, to update internal representations and adjust behavior over time<br>- Can adapt and improve decision-making abilities without explicit programming<br>- Types of learning agents:<br>&emsp;&emsp;1. Supervised learning agents<br>&emsp;&emsp;2. Reinforcement learning agents<br>&emsp;&emsp;3. Unsupervised learning agents    | A recommendation system that learns user preferences and provides personalized recommendations based on previous interactions would be considered learning agent, learns from user feedback and adjusts recommendations to improve accuracy and user satisfaction |\n",
    "\n",
    "```\n",
    "function MODEL-BASED-REFLEX-AGENT(percept) returns an action\n",
    "    persistent: \n",
    "        state, some description of the current world state\n",
    "        transition_model, a description of how the next state depends on current state and action\n",
    "        sensor_model, a description of how current state is determined by percept\n",
    "        rules, a set of condition-action rules\n",
    "        action, the most recent action, initially none\n",
    "\n",
    "    state <- UPDATE-STATE(state, action, percept, transition_model, sensor_model)\n",
    "    rule_match <- RULE-MATCH(state, rules)\n",
    "    action <- rule_match.ACTION\n",
    "    return action\n",
    "```\n",
    "\n",
    "#### Learning agent\n",
    "\n",
    "<img src=\"https://i.stack.imgur.com/IiPoo.png\" width=\"500\" style=\"display: block; margin-left: auto; margin-right: auto; padding-top: 10px; padding-bottom: 10px;\">\n",
    "\n",
    "The four components are:\n",
    "- learning element: makes improvements to the performance element (an example would be Q-learning)\n",
    "- performance element: chooses the actions to take in the environment (this is analogous to a model, e.g. a neural network, that contains the knowledge or rules to act in the environment)\n",
    "- critic: provides feedback (based on some performance metric) to the learning element in order for it to improve the performance element (so this is how you evaluate the potential improvements)\n",
    "- problem generator: suggests actions that will lead to new informative experiences (this would be a behavior policy in reinforcement learning)\n",
    "    \n",
    "```\n",
    "function LEARNING-AGENT-WITH-EXPLORATION(percept) returns an action\n",
    "    persistent:\n",
    "        Q, a table of action values indexed by state and action, initially zero\n",
    "        N, a table of frequencies for state-action pairs, initially zero\n",
    "        s, a, the previous state and action, initially null\n",
    "    if TERMINAL?(s) then Q[s, a] <- R\n",
    "    if s is not null then\n",
    "        increment N[s, a]\n",
    "        Q[s, a] <- Q[s, a] + α(N[s, a])(R + γmaxa'Q[s', a'] - Q[s, a])\n",
    "    if TERMINAL?(s) then s <- null\n",
    "    else s <- s'\n",
    "    if EXPLORE(s) then a <- random action\n",
    "    else a <- argmaxa'Q[s, a']\n",
    "    return a\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
